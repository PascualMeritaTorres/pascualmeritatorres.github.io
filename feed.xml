<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://pascualmeritatorres.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://pascualmeritatorres.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-01-02T23:24:37+00:00</updated><id>https://pascualmeritatorres.github.io/feed.xml</id><title type="html">blank</title><subtitle>My Personal Website.</subtitle><entry><title type="html">Determinism, Free Will, and its relationship with AI</title><link href="https://pascualmeritatorres.github.io/blog/2024/free_will/" rel="alternate" type="text/html" title="Determinism, Free Will, and its relationship with AI"/><published>2024-12-25T16:40:16+00:00</published><updated>2024-12-25T16:40:16+00:00</updated><id>https://pascualmeritatorres.github.io/blog/2024/free_will</id><content type="html" xml:base="https://pascualmeritatorres.github.io/blog/2024/free_will/"><![CDATA[<p><em>in progress.. come back in a few weeks</em></p> <hr/> <p>Picture yourself living in a cabin deep in the forest during the final week of your 3-month spiritual retreat. Your only rule has been to maintain complete silence throughout this time, yet you feel an overwhelming urge to pick up your phone and call your loved ones. Your skin crawls, your hand hovers near the phone, and your mind races: should you break your promise and call them, or wait one more week to honor your goals? After careful consideration, you decide to call. Having spent three months in meditation, you step back and wonder what truly made you pick up the phone. Did you actually make this decision, or was this outcome inevitable? Is there such a thing as careful consideration, or consideration at all? How much does your biological state influence your choices?</p> <p>While I haven’t embarked on a 3-month forest retreat myself, I’ve grappled with these questions since I was 13. In this blog post, I invite you to explore with me the possibility that free will doesn’t exist and how this idea suggests we live in a purely deterministic world. We’ll examine these concepts through the lens of AI and neural networks, which, as a computer scientist, is how I approach these questions.</p> <p>Consider a neural network (in this case, a physical one called the brain) whose initial weights are determined by genetics. You can think of this as the prior in Bayesian statistics. For the first few years of life, this neural network receives input in the form of sensory experiences—sight, smell, touch, taste, and hearing—especially sight and touch. In response to these inputs, driven initially by instinct, it acts and learns from rewards. Touch fire, get burnt. Walk into a wall, get hurt. As time passes, this neural network evolves beyond pure instinct and begins generating latent tokens, which we call inner monologue. This inner monologue can take various forms: language (thinking about what to say), visual imagery (imagining an apple), or audio (a musician conceiving a melody). These latent tokens are fed back into the neural network as input, producing either more latent tokens or actions. The outcomes of these actions are also fed back into the model as a continuous stream of information.</p> <p>If you accept this description of the human brain, an interesting conclusion follows: humans have no free will. All actions are simply generated by a forward pass through a neural network, conditioned by our previous experiences, inner monologue, and genetics. Free will is an illusion.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/free-will.drawio.svg" sizes="95vw"/> <img src="/assets/img/free-will.drawio.svg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Figure 1. System architecture. </div>]]></content><author><name></name></author><category term="personal,"/><category term="ai-related"/><summary type="html"><![CDATA[in progress.. come back in a few weeks]]></summary></entry><entry><title type="html">Books</title><link href="https://pascualmeritatorres.github.io/blog/2024/books/" rel="alternate" type="text/html" title="Books"/><published>2024-12-21T16:40:16+00:00</published><updated>2024-12-21T16:40:16+00:00</updated><id>https://pascualmeritatorres.github.io/blog/2024/books</id><content type="html" xml:base="https://pascualmeritatorres.github.io/blog/2024/books/"><![CDATA[<h2 id="have-read-and-recommend">Have Read (and recommend)</h2> <ul> <li> <p><a href="https://en.wikipedia.org/wiki/Nineteen_Eighty-Four">“1984”</a>, by George Orwell</p> </li> <li> <p><a href="https://en.wikipedia.org/wiki/Animal_Farm">“Animal Farm”</a>, by George Orwell</p> </li> <li> <p><a href="https://en.wikipedia.org/wiki/Brave_New_World">“Brave New World”</a>, by Aldous Huxley</p> </li> <li> <p><a href="https://en.wikipedia.org/wiki/Fahrenheit_451">“Fahrenheit 451”</a>, by Ray Bradbury</p> </li> <li> <p><a href="https://en.wikipedia.org/wiki/G%C3%B6del,_Escher,_Bach">“Gödel, Escher, Bach: An Eternal Golden Braid”</a> by Douglas R. Hofstadter</p> </li> <li> <p><a href="https://en.wikipedia.org/wiki/On_the_Freedom_of_the_Will">“On the Freedom of the Will”</a>, by Arthur Schopenhauer</p> </li> </ul> <h2 id="want-to-read">Want to Read</h2> <ul> <li> <p><a href="https://en.wikipedia.org/wiki/Story_of_Your_Life">“Story of Your Life”</a>, by Ted Chiang</p> </li> <li> <p><a href="https://en.wikipedia.org/wiki/The_Dark_Forest">“The Dark Forest”</a>, by Liu Cixin</p> </li> <li> <p><a href="https://en.wikipedia.org/wiki/Metaphors_We_Live_By">“Metaphors We Live By”</a>, by George Lakoff and Mark Johnson</p> </li> </ul>]]></content><author><name></name></author><category term="useful"/><summary type="html"><![CDATA[Have Read (and recommend)]]></summary></entry><entry><title type="html">My Research Goals</title><link href="https://pascualmeritatorres.github.io/blog/2024/my_research_goals/" rel="alternate" type="text/html" title="My Research Goals"/><published>2024-12-02T16:40:16+00:00</published><updated>2024-12-02T16:40:16+00:00</updated><id>https://pascualmeritatorres.github.io/blog/2024/my_research_goals</id><content type="html" xml:base="https://pascualmeritatorres.github.io/blog/2024/my_research_goals/"><![CDATA[<p>in progress.. come back in a few weeks</p>]]></content><author><name></name></author><category term="ai-related"/><category term="ai-related"/><summary type="html"><![CDATA[in progress.. come back in a few weeks]]></summary></entry><entry><title type="html">Interesting AI Papers or Projects</title><link href="https://pascualmeritatorres.github.io/blog/2024/interesting_ai_papers/" rel="alternate" type="text/html" title="Interesting AI Papers or Projects"/><published>2024-11-25T16:40:16+00:00</published><updated>2024-11-25T16:40:16+00:00</updated><id>https://pascualmeritatorres.github.io/blog/2024/interesting_ai_papers</id><content type="html" xml:base="https://pascualmeritatorres.github.io/blog/2024/interesting_ai_papers/"><![CDATA[<p>in progress.. come back in a few weeks</p> <h4 id="vision">Vision</h4> <ul> <li><a href="https://diamond-wm.github.io/">Diffusion for World Modeling: Visual Details Matter in Atari</a></li> </ul> <hr/> <h4 id="natural-language-processing">Natural Language Processing</h4> <ul> <li> <p><a href="https://arxiv.org/pdf/2411.12580">Procedural Knowledge in Pretraining Drives Reasoning in Large Language Models</a></p> </li> <li> <p><a href="https://arxiv.org/pdf/2403.09636">Dynamic Memory Compression: Retrofitting LLMs for Accelerated Inference</a></p> </li> </ul> <h4 id="agents">Agents</h4> <ul> <li><a href="https://github.com/SakanaAI/AI-Scientist">SakanaAI’s AI Scientist</a> and its associated <a href="https://arxiv.org/pdf/2408.06292">paper</a></li> </ul> <h4 id="open-endedness">Open-Endedness</h4>]]></content><author><name></name></author><category term="ai-related"/><summary type="html"><![CDATA[in progress.. come back in a few weeks]]></summary></entry><entry><title type="html">Interesting AI Researchers</title><link href="https://pascualmeritatorres.github.io/blog/2024/interesting_ai_researchers/" rel="alternate" type="text/html" title="Interesting AI Researchers"/><published>2024-11-25T16:40:16+00:00</published><updated>2024-11-25T16:40:16+00:00</updated><id>https://pascualmeritatorres.github.io/blog/2024/interesting_ai_researchers</id><content type="html" xml:base="https://pascualmeritatorres.github.io/blog/2024/interesting_ai_researchers/"><![CDATA[<p>in progress.. come back in a few weeks</p>]]></content><author><name></name></author><category term="ai-related"/><summary type="html"><![CDATA[in progress.. come back in a few weeks]]></summary></entry><entry><title type="html">Small reasoner-like models vs. large knowledge-dense models</title><link href="https://pascualmeritatorres.github.io/blog/2024/small_vs_big_models/" rel="alternate" type="text/html" title="Small reasoner-like models vs. large knowledge-dense models"/><published>2024-11-25T16:40:16+00:00</published><updated>2024-11-25T16:40:16+00:00</updated><id>https://pascualmeritatorres.github.io/blog/2024/small_vs_big_models</id><content type="html" xml:base="https://pascualmeritatorres.github.io/blog/2024/small_vs_big_models/"><![CDATA[<p><em>in progress.. come back in a few weeks</em></p> <hr/> <p>I am currently working on the literature review, but in the mean time, this is what I roughly want to cover:</p> <ol> <li> <p><strong>Small reasoner-like models</strong>. Motivated by Retrieval Augmented Generation (RAG), I envision a pipeline where there is an information seeking step, and a generation step. The generation step is performed by a smaller model which just focuses on reasoning over data. The two steps are coupled, creating a loop where the reasoner can ask for an extra retrieval step (indefinitely in theory). This kind of pipeline already exists, but I believe it is not yet fully exploited. I will expand more on why I believe this is the case in the article.</p> </li> <li> <p><strong>Large knowledge-dense models</strong>. Motivated by (1) the on-going research on updating the parametric knowledge of models, (2) the success of increasing the context window of LLMs, and (3) the trend of making LLMs larger and larger, I envision a pipeline where models can be constantly updated with new data (to the minute), massive amounts of data can be put in-context, and the model itself can store a lot of information in its parameters. In this pipeline, there is no need for external knowledge bases, as the model itself can act as a knowledge base and can be updated every day or multiple times a day. All the private information about a specific user/system can be put in-context.</p> </li> <li> <p><strong>Hybrid models</strong>. There are multiple ways to combine the two worlds/paradigms that I mentioned above. This is where the main body of my literature review will be focused on, as it is the part that I know the least about. An obvious way of combining it is through traditional RAG, where a (small or large) model is used to select which documents to retrieve, and then a large model is used to reason over the retrieved documents. Another (more experimental) way that I can think of is to have a sparse mixture of experts, where there is a small router model that is used to select which expert to use. Each expert can either be a small reasoner-like model or a large model. Another hybrid model that I can think of is a large model that has a reasoner-like module or system embedded in it. This is where all the recent research on reasoning is headed towards. Research such as Star, and Quiet Star (any research focused on scaling inference time compute). I will expand more on this in the article.</p> </li> </ol>]]></content><author><name></name></author><category term="ai-related"/><summary type="html"><![CDATA[in progress.. come back in a few weeks]]></summary></entry><entry><title type="html">Cool Music Performances (only live performances)</title><link href="https://pascualmeritatorres.github.io/blog/2024/cool_music_performances/" rel="alternate" type="text/html" title="Cool Music Performances (only live performances)"/><published>2024-11-05T16:40:16+00:00</published><updated>2024-11-05T16:40:16+00:00</updated><id>https://pascualmeritatorres.github.io/blog/2024/cool_music_performances</id><content type="html" xml:base="https://pascualmeritatorres.github.io/blog/2024/cool_music_performances/"><![CDATA[<p>A big part of my life revolves around music. I am classicaly trained on piano by the Professional Conservatory of Music of Valencia, Spain, and I have been producing (electronic) music since the age of 14 or so. This blog serves as a display of my music taste, with the hope that I can find people with a similar taste (surprisingly this has been very difficult).</p> <p>The only requirement for this recopilation of music performances is that they are live (or pseudo-live).</p> <p>Please also note that this list is heeeavily skewed towards my 4 favourite artists: Jungle, Parcels, Jamiroquai, and Dabeull. It is also heavily skewed towards the bands that release studio quality recordings of their live performances.</p> <hr/> <ul> <li> <p><a href="https://www.youtube.com/watch?v=e8rpp-8a5s0">Jungle - Busy Earnin’, Glastonbury 2019</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=x1J6ZbKtHpw">Jungle - Busy Earnin’, Music For Life 2018</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=e4TFD2PfVPw&amp;t=1182s">Parcels - Live Vol. 1</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=H1JP759pHxI&amp;t=6110s">Parcels - Live from Red Rocks, Colorado</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=wJgRT6YDhVM&amp;list=PL1lFqScOmwRgJl_lx8o6bnvNyeAwxTHLi&amp;index=49">Parcels - Myenemy (Live @ Funkhaus Berlin)</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=Gb1Z71JfI6E&amp;list=PL1lFqScOmwRgJl_lx8o6bnvNyeAwxTHLi&amp;index=45">Parcels - Hideout (Live @ Funkhaus Berlin)</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=Zy4KtD98S2c">RÜFÜS DU SOL - Live from Joshua Tree</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=r4C6Kgrloxc">Anderson Paak &amp; Mac Miller- Dang! - Live</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=WZTq5do8v4s">FKJ &amp; Tom Misch - Losing My Way (Live from O2 Academy Brixton)</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=pfU0QORkRpY">FKJ, Ylang Ylang EP</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=r2IoFgYV3IA&amp;list=PLJbhug9IoSL1EvNiCoj_yjAI2tHuBYJSF&amp;index=33">FKJ - Live at MELT 2019</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=hM2xWRRYA-k">FKJ - Canguu</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=M1N_wbhAfQ4">Tom Misch - It Runs Through Me</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=PmC9FsfUzy0">L’Impératrice @ La Felicità for Drop</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=SW6L_lTrIFg">C. Tangana: Tiny Desk (Home) Concert</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=pnUQYxjaWB4">Oracle Sisters - Asc. Scorpio / Tramp Like You / RBH</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=oTKz4MPd9Jw">Dabeull Band - Sweet Baby</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=Ik4DBIu8Igc">Dabeull Band - Live in Paris</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=IUJTRkrYFwo">Dabeull &amp; Rude Jude - Indastudio</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=13akCBtddRk">Dabeull - So Many Hands - Indastudio</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=gSsOJfXHk00">HER - Five Minutes - Live at JITWVHQ</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=1c1Fp8NRzrs">L’Impératrice — VACANCES (Live à Dour)</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=1XNpsjpOI8A&amp;list=PLJbhug9IoSL1EvNiCoj_yjAI2tHuBYJSF&amp;index=21">Air - La Femme d’Argent</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=rlzyFxqWYaY&amp;list=PLJbhug9IoSL1EvNiCoj_yjAI2tHuBYJSF&amp;index=23">Vulfpeck - Beastly</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=qT41uNtvmmA">Jamiroquai - Virtual Insanity (Live in Verona)</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=Yi0QlZZ2qo8">Jamiroquai - Little L (Live in Verona)</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=ct7ad4FhuJI&amp;list=RDGMEMP-96bLtob-xyvCobnxVfyw&amp;start_radio=1&amp;rv=j8EX6i8hqqo">Jamiroquai - Time Won’t Wait (Live at Scala, London 2007)</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=rMcEwaGz_64&amp;list=RDGMEMP-96bLtob-xyvCobnxVfyw&amp;index=3">Jamiroquai - Bad Girls / Singin’ in the Rain (Live in Verona)</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=pRERgcQe-fQ">Nile Rodgers &amp; CHIC: Tiny Desk Concert</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=ypG3QUydnaw">Bellaire &amp; Georges - Contrasts</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=n5VRejmpMV8">Mayer Hawthorne - Henny &amp; Gingerale</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=32QLuWFfDJY&amp;list=RDGMEMJQXQAmqrnmK1SEjY_rKBGA&amp;index=4">HÆLOS - Pray (Live on KEXP)</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=6sk-AWElVgM">Simply Broke - La Infinita (Mashup)</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=TWxeMtklESw">Simply Broke - I wanna Be Like You (Cover)</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=jtAg8_ltDEo">Michael Jackson - Don’t Stop Til You Get Enough</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=buCdGwH2Efc">Michael Jackson - Earth Song</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=NbAeffcXRe0">BB &amp; Q Band - On The Beat</a></p> </li> </ul>]]></content><author><name></name></author><category term="personal"/><summary type="html"><![CDATA[A big part of my life revolves around music. I am classicaly trained on piano by the Professional Conservatory of Music of Valencia, Spain, and I have been producing (electronic) music since the age of 14 or so. This blog serves as a display of my music taste, with the hope that I can find people with a similar taste (surprisingly this has been very difficult).]]></summary></entry><entry><title type="html">Useful Blogs (written by other people)</title><link href="https://pascualmeritatorres.github.io/blog/2024/useful_blogs/" rel="alternate" type="text/html" title="Useful Blogs (written by other people)"/><published>2024-11-05T16:40:16+00:00</published><updated>2024-11-05T16:40:16+00:00</updated><id>https://pascualmeritatorres.github.io/blog/2024/useful_blogs</id><content type="html" xml:base="https://pascualmeritatorres.github.io/blog/2024/useful_blogs/"><![CDATA[<p>This is a carefully curated (and still incomplete) collection of blogposts which in my opinion are worth a read. I’m positively surprised by the sheer amount of influential (and not so influential) people that spend a lot of their free time writing down their thoughts and learnings. Enjoy!</p> <hr/> <h2 id="ai-related-technical">AI-related (Technical)</h2> <h4 id="classics">Classics</h4> <ul> <li> <p>Richard Sutton’s <a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">The Bitter Lesson</a>. My biggest takeaway from it is that</p> <blockquote> <p>“building how we think we think does not work in the long run”</p> </blockquote> </li> </ul> <h4 id="non-classics-yet">Non-Classics (Yet)?</h4> <ul> <li> <p>Evan Miller´s <a href="https://www.evanmiller.org/attention-is-off-by-one.html">Attention is Off By One</a></p> </li> <li> <p>Aidan McLaughlin’s <a href="https://aidanmclaughlin.notion.site/reasoners-problem">The Problem with (LLM) Reasoners</a></p> </li> <li> <p>Yi Tay’s <a href="https://www.yitay.net/blog/model-architecture-blogpost-encoders-prefixlm-denoising">What happened to BERT &amp; T5? On Transformer Encoders, PrefixLM and Denoising Objectives</a></p> </li> </ul> <hr/> <h2 id="ai-related-non-technical">AI-related (Non-Technical)</h2> <ul> <li> <p>Tim Rocktäschel’s <a href="https://rockt.github.io/2018/08/29/msc-advice">Advice for Short-term Machine Learning Research Projects</a></p> </li> <li> <p>Mor Harchol-Balter’s <a href="https://www.cs.cmu.edu/~harchol/gradschooltalk.pdf">Applying to Ph.D. Programs in CS</a></p> </li> <li> <p>Andrej Karpathy’s <a href="https://karpathy.github.io/2016/09/07/phd/">A Survival Guide to a PhD</a>, which in my opinion is completely generalisable to doing research in general, not only during a PhD. In fact, I think some of his thoughts (such as developing taste) are applicable to working in almost any job in general.</p> </li> <li> <p>Jason Eisner’s <a href="https://www.cs.jhu.edu/~jason/advice/how-to-read-a-paper.html">How to Read a Paper</a></p> </li> <li> <p>Jason Eisner’s <a href="https://www.cs.jhu.edu/~jason/advice/write-the-paper-first.html?ref=ruder.io">Write the Paper First</a></p> <blockquote> <p>There are 2 reasons a paper will be cited. 1) If you have a great implementation that people can just use as a black box. 2) Otherwrise, your paper is only useful for the ideas that it provides.</p> </blockquote> </li> <li> <p>Sebastian Ruder’s <a href="https://www.ruder.io/10-tips-for-research-and-a-phd/#1-read-broadly-">10 Tips for Research and a PhD</a></p> </li> <li> <p>Richard Hamming’s <a href="https://www.cs.virginia.edu/~robins/YouAndYourResearch.html?ref=ruder.io">You and Your Research</a></p> </li> <li> <p>Jakob Foerster’s <a href="https://docs.google.com/document/d/16R1E2ExKUCP5SlXWHr-KzbVDx9DBUclra-EbU8IB-iE/edit?tab=t.0#heading=h.16t67gkeu9dx">How to ML Paper</a></p> </li> <li> <p>Tim Dettmers’s <a href="https://timdettmers.com/2018/11/26/phd-applications/">Machine Learning PhD Applications - Everything You Need to Know</a></p> </li> </ul> <h2 id="personal-life">Personal Life</h2> <ul> <li> <p>Spruce Campbell’s <a href="https://spruce.world/blog/dont-ask-successful-people-for-advice.html">Don´t Ask Successful People for Advice</a>, instead ask for criticism.</p> <blockquote> <p>(If you ask for criticism, ) what they say to you is probably going to be much more actionable, direct and sensible than if you asked for generic advice.</p> </blockquote> </li> <li> <p>Spruce Campbell’s <a href="https://spruce.world/blog/talking-to-geniuses.html">Talking to Geniuses</a></p> </li> <li> <p>Paul Graham’s <a href="https://www.paulgraham.com/persistence.html#f1n">The Right Kind of Stubborn</a></p> <blockquote> <p>The persistent (good kind of stubborn) are attached to the goal. The obstinate (bad kind of stubborn) are attached to their ideas about how to reach it.</p> </blockquote> </li> <li> <p>Sam Altman’s <a href="https://blog.samaltman.com/how-to-be-successful">How to Be Successful</a></p> <blockquote> <p>It is much more important to work on the right thing than it is to work many hours.</p> </blockquote> </li> <li> <p>Paul Graham’s <a href="https://paulgraham.com/taste.html">Taste for Makers</a></p> <blockquote> <p>When you’re forced to be simple, you’re forced to face the real problem. When you can’t deliver ornament, you have to deliver substance.</p> </blockquote> </li> </ul>]]></content><author><name></name></author><category term="useful"/><summary type="html"><![CDATA[This is a carefully curated (and still incomplete) collection of blogposts which in my opinion are worth a read. I’m positively surprised by the sheer amount of influential (and not so influential) people that spend a lot of their free time writing down their thoughts and learnings. Enjoy!]]></summary></entry><entry><title type="html">Useful Podcasts / Videos</title><link href="https://pascualmeritatorres.github.io/blog/2024/useful_podcasts/" rel="alternate" type="text/html" title="Useful Podcasts / Videos"/><published>2024-11-05T16:40:16+00:00</published><updated>2024-11-05T16:40:16+00:00</updated><id>https://pascualmeritatorres.github.io/blog/2024/useful_podcasts</id><content type="html" xml:base="https://pascualmeritatorres.github.io/blog/2024/useful_podcasts/"><![CDATA[<p>Some (or I should probably say a lot) of the content that I consume on a daily basis is in the form of podcasts or youtube videos in general. This is an incomplete collection of all of the ones that might be useful to someone with a similar background to me.</p> <hr/> <h2 id="ai-related">AI-related</h2> <h4 id="classics">Classics</h4> <ul> <li> <p><a href="https://www.youtube.com/watch?v=13CZPWmke6A">Ilya Sutskever</a> on the Lex Fridman Podcast</p> </li> <li> <p><a href="https://www.youtube.com/watch?v=cdiD-9MMpb0&amp;t=6209s">Andrej Karpathy</a> on the Lex Fridman Podcast</p> </li> </ul> <h4 id="non-classics-yet">Non-Classics (Yet)?</h4> <ul> <li> <p><a href="https://www.youtube.com/watch?v=ugvHCXCOmm4&amp;t=1069s">Dario Amoidei</a> on the Lex Fridman Podcast</p> </li> <li> <p>Sasha Rush’s <a href="https://www.youtube.com/watch?v=6PEJ96k1kiw&amp;t=593s">Speculations on Test-Time Scaling (o1)</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=oFfVt3S51T4&amp;t=7426s">Cursor team</a> on the Lex Fridman Podcast</p> </li> <li> <p><a href="https://www.youtube.com/watch?v=WXuK6gekU1Y">AlphaGo Documentary</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=rgP_LBtaUEc">PyTorch Documentary</a></p> </li> <li> <p><a href="https://www.youtube.com/watch?v=Yf1o0TQzry8">Ilya Sutskever</a> on Dwarkesh Patel’s Podcast</p> </li> <li> <p><a href="https://www.youtube.com/watch?v=n4IQOBka8bc">Geoffrey Hinton</a> on Sana’s channel</p> </li> <li> <p>Noam Brown’s lecture on <a href="https://www.youtube.com/watch?v=Gr_eYXdHFis"> Learning to Reason with LLMs</a></p> </li> </ul>]]></content><author><name></name></author><category term="useful"/><summary type="html"><![CDATA[Some (or I should probably say a lot) of the content that I consume on a daily basis is in the form of podcasts or youtube videos in general. This is an incomplete collection of all of the ones that might be useful to someone with a similar background to me.]]></summary></entry></feed>